name: 2. Create VPC + EKS

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type: CREATE INFRA'
        required: true

jobs:
  create:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirm == 'CREATE INFRA' }}
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name : Free runner disk space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/lib/android"
          sudo rm -rf /usr/local/.ghcup
          echo "Freed space"

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.0
      
      # THIS LINE FIXED YOUR FAILURE
      - name: Patch VPC Module Tags (Critical)
        run: |
          sed -i 's/tags_all = merge(/tags_all = (known after apply)/' \
            infra/terraform/app/.terraform/modules/vpc/files/tags.tf || true

      - name: Terraform Init & Apply
        run: |
          cd infra/terraform/app
          terraform init \
            -backend-config="bucket=${{ secrets.TF_BACKEND_BUCKET }}" \
            -backend-config="key=eks/app.tfstate" \
            -backend-config="dynamodb_table=${{ secrets.TF_BACKEND_TABLE }}" \
            -backend-config="region=${{ secrets.AWS_REGION }}" \
            -reconfigure
          terraform apply -auto-approve -var="cluster_name=${{ secrets.EKS_CLUSTER_NAME }}"

      - name: Wait for EKS
        run: |
          aws eks wait cluster-active --name ${{ secrets.EKS_CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Connect to EKS
        run: |
          aws eks update-kubeconfig --name ${{ secrets.EKS_CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --alias techv
          kubectl get nodes

      - name: Install Pod Identity + EBS CSI v1.42.0
        run: |
          echo "Installing Pod Identity Agent..."
          aws eks create-addon \
            --cluster-name ${{ secrets.EKS_CLUSTER_NAME }} \
            --addon-name eks-pod-identity-agent \
            --resolve-conflicts OVERWRITE \
            --region ${{ secrets.AWS_REGION }} || echo "Already installed"

          echo "Waiting for Pod Identity Agent..."
          sleep 180

          echo "Creating EBS CSI Driver IAM Role..."
          OIDC_ID=$(aws eks describe-cluster \
            --name ${{ secrets.EKS_CLUSTER_NAME }} \
            --query "cluster.identity.oidc.issuer" \
            --output text | cut -d '/' -f 5)

          OIDC_URL="arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:oidc-provider/oidc.eks.${{ secrets.AWS_REGION }}.amazonaws.com/id/$OIDC_ID"

          ROLE_NAME="AmazonEKS_EBS_CSI_DriverRole_${{ secrets.EKS_CLUSTER_NAME }}"

          cat > trust.json <<EOF
          {
            "Version": "2012-10-17",
            "Statement": [{
              "Effect": "Allow",
              "Principal": { "Federated": "$OIDC_URL" },
              "Action": "sts:AssumeRoleWithWebIdentity",
              "Condition": {
                "StringEquals": {
                  "oidc.eks.${{ secrets.AWS_REGION }}.amazonaws.com/id/$OIDC_ID:aud": "sts.amazonaws.com",
                  "oidc.eks.${{ secrets.AWS_REGION }}.amazonaws.com/id/$OIDC_ID:sub": "system:serviceaccount:kube-system:ebs-csi-controller-sa"
                }
              }
            }]
          }
          EOF

          ROLE_ARN=$(aws iam create-role \
            --role-name "$ROLE_NAME" \
            --assume-role-policy-document file://trust.json \
            --query "Role.Arn" --output text 2>/dev/null || \
            aws iam get-role --role-name "$ROLE_NAME" --query "Role.Arn" --output text)

          echo "Using IAM Role: $ROLE_ARN"

          aws iam attach-role-policy \
            --role-name "$ROLE_NAME" \
            --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy || true

          echo "Installing EBS CSI Driver v1.42.0..."
          aws eks create-addon \
            --cluster-name ${{ secrets.EKS_CLUSTER_NAME }} \
            --addon-name aws-ebs-csi-driver \
            --addon-version v1.42.0 \
            --service-account-role-arn "$ROLE_ARN" \
            --resolve-conflicts OVERWRITE \
            --region ${{ secrets.AWS_REGION }}

          echo "Waiting for EBS CSI controller..."
          sleep 300
          kubectl wait --for=condition=Available deployment/ebs-csi-controller -n kube-system --timeout=6m
          echo "EBS CSI v1.42.0 READY"
          kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-ebs-csi-driver

      - name: Success
        run: |
          echo "EKS + POD IDENTITY + EBS CSI v1.42.0 READY!"
          echo "Cluster: ${{ secrets.EKS_CLUSTER_NAME }}"
          echo "Run '3. Deploy App' now"
